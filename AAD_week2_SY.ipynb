{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNSIT_data/\", one_hot=True)\n# mnist is a complex Python object", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Extracting MNSIT_data/train-images-idx3-ubyte.gz\nExtracting MNSIT_data/train-labels-idx1-ubyte.gz\nExtracting MNSIT_data/t10k-images-idx3-ubyte.gz\nExtracting MNSIT_data/t10k-labels-idx1-ubyte.gz\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "import tensorflow as tf ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 4
        }, 
        {
            "source": "%matplotlib inline\nimport  matplotlib.pyplot as plt", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "batch_xs, batch_ys = mnist.train.next_batch(1)\n# this is a  one hot encoded vector: the index of the actual corresponding number, we see on, and all the other elements are zero\n#now we will access 1 at a time image fromm 55,000 from the MNIST training set\nX = batch_xs\nX = X.reshape([28,28])\n# images in the Mnist dta set are 28 by 28 pixels. \n# but we are only optaining a vector of 784 pixel's length, so we have to reshape it\nplt.gray()\nprint(batch_ys)\nplt.imshow(X)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]]\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "<matplotlib.image.AxesImage at 0x7ff83c22b0b8>"
                    }, 
                    "execution_count": 21, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADadJREFUeJzt3V+oXeWZx/Hvo2lvbC/8EzVYm3SK\nREcvbIwy0BqUYnGGgkexUiGY0nHSi4rWzMXE5KKCmJRh7MxcFTMYmkJqW0zOKCLTihRTYVCTMFTr\nSVspmSRjyB8t1BKhGJ+5OOvMnOrZ7zo5+8/aJ+/3A+HsvZ+99nqyk99Za+93rfVGZiKpPud03YCk\nbhh+qVKGX6qU4ZcqZfilShl+qVKGX6qU4ZcqZfilSi0Z5coiwsMJpSHLzJjP8/ra8kfErRHx64h4\nMyI29vNakkYrFnpsf0ScC/wGuAU4ArwK3J2ZbxSWccsvDdkotvw3AG9m5u8y80/Aj4Db+ng9SSPU\nT/gvAw7Pun+keezPRMT6iNgbEXv7WJekAevnC7+5di0+slufmduAbeBuvzRO+tnyHwEun3X/U8Bb\n/bUjaVT6Cf+rwBUR8ZmI+DjwVeCZwbQladgWvNufme9HxH3AT4Fzge2Z+auBdSZpqBY81LeglfmZ\nXxq6kRzkI2nxMvxSpQy/VCnDL1XK8EuVMvxSpQy/VCnDL1XK8EuVMvxSpQy/VCnDL1XK8EuVMvxS\npQy/VCnDL1XK8EuVMvxSpQy/VCnDL1XK8EuVGukU3Vp8li5dWqyvXbu2WJ+YmOhZu/HGG4vLtl1Z\nesuWLcX61q1be9ZOnTpVXLYGbvmlShl+qVKGX6qU4ZcqZfilShl+qVKGX6pUX7P0RsRB4F3gNPB+\nZq5ueb6z9I6ZtnH85557rlhftWpVsV76/xVRnky27f9m2/L33HNPz9rOnTuLyy5m852ldxAH+dyc\nmScH8DqSRsjdfqlS/YY/gZ9FxL6IWD+IhiSNRr+7/Z/PzLci4mLg+Yg4kJl7Zj+h+aXgLwZpzPS1\n5c/Mt5qfx4FJ4IY5nrMtM1e3fRkoabQWHP6IOC8iPjlzG/gS8PqgGpM0XP3s9l8CTDbDLUuAH2bm\nfwykK0lD19c4/xmvzHH+kWsbx3/xxReL9ZUrVxbrhw8fLtYff/zxnrXS+fYAmzdvLtYfeeSRYn1q\naqpn7eqrry4uu5jNd5zfoT6pUoZfqpThlypl+KVKGX6pUoZfqpRDfWeB0nDeME/JBbj00kuL9ZMn\nh3fC5+nTp4v1Uu9Llpy9V613qE9SkeGXKmX4pUoZfqlShl+qlOGXKmX4pUqdvYOdZ5G203Lvv//+\nnrW2cfy2qaqvv/76Yr2fcfzly5cX66+88kqx3nbp7snJyTPuqSZu+aVKGX6pUoZfqpThlypl+KVK\nGX6pUoZfqpTj/IvAQw89VKw/8MADPWtt5+OXprEGOHDgQLE+TG29ly4LDu2XBq+dW36pUoZfqpTh\nlypl+KVKGX6pUoZfqpThlyrVet3+iNgOfBk4npnXNI9dAPwYWAEcBO7KzN+3rszr9s+p3/PaS+f7\n7969u7jsnXfeWaxr8Rnkdfu/D9z6occ2Ai9k5hXAC819SYtIa/gzcw/wzocevg3Y0dzeAUwMuC9J\nQ7bQz/yXZOZRgObnxYNrSdIoDP3Y/ohYD6wf9noknZmFbvmPRcQygObn8V5PzMxtmbk6M1cvcF2S\nhmCh4X8GWNfcXgc8PZh2JI1Ka/gj4kngP4GVEXEkIv4W+A5wS0T8FriluS9pEWn9zJ+Zd/cofXHA\nvVTr3nvvLdYvvPDCYv3EiRM9axs2bFhQTzr7eYSfVCnDL1XK8EuVMvxSpQy/VCnDL1XKS3ePgbYp\nuNumoj506NCCaqqbW36pUoZfqpThlypl+KVKGX6pUoZfqpThlyrlOP8i0HZ59bbLc0tzccsvVcrw\nS5Uy/FKlDL9UKcMvVcrwS5Uy/FKlHOcfA2vWrCnW287nP3DgwCDbUSXc8kuVMvxSpQy/VCnDL1XK\n8EuVMvxSpQy/VKloO1c8IrYDXwaOZ+Y1zWMPA38HzMwNvSkzn2tdWUR5ZZU6ffp0sd72b7RkiYdr\n6P9lZvnAkMZ8tvzfB26d4/F/zsxrmz+twZc0XlrDn5l7gHdG0IukEernM/99EfHLiNgeEecPrCNJ\nI7HQ8H8P+CxwLXAUeKzXEyNifUTsjYi9C1yXpCFo/cIPICJWAM/OfOE339ocz/ULvzn4hZ8GaZBf\n+H1ERCybdfd24PWFvI6k7rRuMiLiSeAm4KKIOAJ8G7gpIq4FEjgIfGOIPUoagtbwZ+bdczz8xBB6\nqVbb+fqTk5PF+nXXXdezNjExUVx26dKlxXqbl156qVifmprqWdu3b19f61Z/PMJPqpThlypl+KVK\nGX6pUoZfqpThlyo1ryP8BrYyj/CbU79H+JWGCvtZdtjLP//888VlH3300WK9bZixVkM9wk/S4mf4\npUoZfqlShl+qlOGXKmX4pUoZfqlSjvOPwO23316s79q1q1hv+zc6fPhwz9qJEyd61uajdEouwFVX\nXVWsX3TRRT1ry5cvLy7b9vfesmVLsb5169aetVOnThWXXcwc55dUZPilShl+qVKGX6qU4ZcqZfil\nShl+qVJO9TICbeP8bePZbfXdu3f3rG3YsKG47LCVxvlLlxwH2LFjR7G+adOmYv3AgQM9azt37iwu\nWwO3/FKlDL9UKcMvVcrwS5Uy/FKlDL9UKcMvVar1fP6IuBz4AXAp8AGwLTP/NSIuAH4MrAAOAndl\n5u9bXqvK8/nbbN68uVjfuHFjsf7ee+/1rLWd89423t3v9QD6ceWVVxbrpeMbAFauXNmzdvPNNxeX\n3bNnT7E+zgZ5Pv/7wN9n5lXAXwHfjIi/BDYCL2TmFcALzX1Ji0Rr+DPzaGbub26/C0wBlwG3ATOH\nYO0AJobVpKTBO6PP/BGxAvgc8DJwSWYehelfEMDFg25O0vDM+9j+iPgEsAv4Vmb+oW2OtlnLrQfW\nL6w9ScMyry1/RHyM6eDvzMyZb1mORcSypr4MOD7Xspm5LTNXZ+bqQTQsaTBawx/Tm/gngKnM/O6s\n0jPAuub2OuDpwbcnaVjmM9T3BeAXwGtMD/UBbGL6c/9PgE8Dh4CvZOY7La/lUN8CtJ0S/NRTT/Ws\n9XPZb4Bt27YV62+//XaxXrJ06dJifWKi/B3yqlWrivU33nijZ61tqO/kyZPF+jib71Bf62f+zHwJ\n6PViXzyTpiSND4/wkypl+KVKGX6pUoZfqpThlypl+KVKOUX3WWDNmjU9a4899lhx2dWrywdefvDB\nB8X6OeeUtx+l5ftZFtqPUXjwwQd71iYnJ4vLLmZO0S2pyPBLlTL8UqUMv1Qpwy9VyvBLlTL8UqUc\n5z/LlabIBli7dm2xXrr8NcAdd9xRrLddXrukbSx+//79xfpiPie/H47zSyoy/FKlDL9UKcMvVcrw\nS5Uy/FKlDL9UKcf5pbOM4/ySigy/VCnDL1XK8EuVMvxSpQy/VCnDL1WqNfwRcXlE/DwipiLiVxHx\nQPP4wxHxPxHxX82fvxl+u5IGpfUgn4hYBizLzP0R8UlgHzAB3AX8MTP/ad4r8yAfaejme5DPknm8\n0FHgaHP73YiYAi7rrz1JXTujz/wRsQL4HPBy89B9EfHLiNgeEef3WGZ9ROyNiL19dSppoOZ9bH9E\nfAJ4EXg0M3dHxCXASSCBR5j+aPD1ltdwt18asvnu9s8r/BHxMeBZ4KeZ+d056iuAZzPzmpbXMfzS\nkA3sxJ6ICOAJYGp28JsvAmfcDrx+pk1K6s58vu3/AvAL4DVgZs7kTcDdwLVM7/YfBL7RfDlYei23\n/NKQDXS3f1AMvzR8ns8vqcjwS5Uy/FKlDL9UKcMvVcrwS5Uy/FKlDL9UKcMvVcrwS5Uy/FKlDL9U\nKcMvVcrwS5VqvYDngJ0E/nvW/Yuax8bRuPY2rn2BvS3UIHtbPt8njvR8/o+sPGJvZq7urIGCce1t\nXPsCe1uornpzt1+qlOGXKtV1+Ld1vP6Sce1tXPsCe1uoTnrr9DO/pO50veWX1JFOwh8Rt0bEryPi\nzYjY2EUPvUTEwYh4rZl5uNMpxppp0I5HxOuzHrsgIp6PiN82P+ecJq2j3sZi5ubCzNKdvnfjNuP1\nyHf7I+Jc4DfALcAR4FXg7sx8Y6SN9BARB4HVmdn5mHBErAH+CPxgZjakiPhH4J3M/E7zi/P8zPyH\nMentYc5w5uYh9dZrZumv0eF7N8gZrwehiy3/DcCbmfm7zPwT8CPgtg76GHuZuQd450MP3wbsaG7v\nYPo/z8j16G0sZObRzNzf3H4XmJlZutP3rtBXJ7oI/2XA4Vn3jzBeU34n8LOI2BcR67tuZg6XzMyM\n1Py8uON+Pqx15uZR+tDM0mPz3i1kxutB6yL8c80mMk5DDp/PzFXAXwPfbHZvNT/fAz7L9DRuR4HH\numymmVl6F/CtzPxDl73MNkdfnbxvXYT/CHD5rPufAt7qoI85ZeZbzc/jwCTTH1PGybGZSVKbn8c7\n7uf/ZOaxzDydmR8A/0aH710zs/QuYGdm7m4e7vy9m6uvrt63LsL/KnBFRHwmIj4OfBV4poM+PiIi\nzmu+iCEizgO+xPjNPvwMsK65vQ54usNe/sy4zNzca2ZpOn7vxm3G604O8mmGMv4FOBfYnpmPjryJ\nOUTEXzC9tYfpMx5/2GVvEfEkcBPTZ30dA74N/DvwE+DTwCHgK5k58i/eevR2E2c4c/OQeus1s/TL\ndPjeDXLG64H04xF+Up08wk+qlOGXKmX4pUoZfqlShl+qlOGXKmX4pUoZfqlS/wtId2SSBY8zFAAA\nAABJRU5ErkJggg==\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7ff83c253c18>"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 21
        }, 
        {
            "source": "x = tf.placeholder(tf.float32, [None, 784])\n# placeholder: tense sevice in Tensorflow that data is fed in during excution time\n# this is used  to add data during training, which takes place after this computation graph is constructed\n# placeholders are typed and we can use either sngle or a double position\n# so this placeholder will take our training vectors,\n#representing the images, the 784 elements inside\nW = tf.Variable(tf.zeros([784,10]))\n# a variable is sth Tensorflow retrieve during training whereas the placehlder is meant to keep training data\n# in additon a variable can be saved to disk during and after training for check pointing and water transfer\n# we create our weight matrix W with 784 bytes on one X's\n# just one for each element of X, and we do it 10 times\n# since we are basically running 10 soft mix regression motors in pararell\n# one for each possible digit\nb = tf.Variable(tf.zeros([10]))\n# finally we end up with a bias that draw one foot each soft next regression model\ny = tf.nn.softmax(tf.matmul(x,W)+b)\n# be aware that no computating is happening at this stage\n# we are not basically hooking up the notes together to form a computing of graph\n# softmax as well as Matmul expect Tensorflow variables as Polanyi does\n# we are just despiting the expressive computation of graph\n# whic is executed bt the Tensorflow engine in the background\n#Tensorflow is not having it's own domain specific language for doing so,\n#but it's relying on language bindings in different programming languages", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 9
        }, 
        {
            "source": "y_ = tf.placeholder(tf.float32, [None,10])\n# creating another placeholder for a training level spike\n# These are often mentioned 10, because why? It is the one hot encoded vector labeling the image.", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 11
        }, 
        {
            "source": "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n# Now we defined the cost function as cross-entropy. \n#Therefore, let me just walk you through the formula and we will see later how to implement it in TensorFlow. \n#So we take a predictive value of Y head and multiply it to the log of the desired value of Y and some of those values up. \n#So we start with the reduce mean function of TensorFlow, \n#because we are now calculating 10 individual cross-entrophy values, one for each softmax regression model. \n#Then we use Reduce Sum, to calculate the sum of the individual values of a Tensor. \n#And this Tensor is the product of the desired value, and the luck of the actual prediction.\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n#Reduction indices defines that the dimension of the Tensor that aggregation should take place. \n#Since Y is a matrix of 10 columns and N rows, \n#he N stands for a number of creating examples, the sum over the columns to obtain the value for each digit. \n#This reside has no past to an argument to reduce mean, \n#so that the overall prediction error is calculated all of the individual prediction errors for each number between zero and nine.\n#Now, we use TensorFlow GradientDescentOptimizer with the learning rate of zero to five, \n# to tweak W and B with respect to the cross-entropy function. \n#So TensorFlow will take care of calculating the back propagation and gradients for this task automatically. \n#A feature called automatic differentiation, does the job for us.", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 13
        }, 
        {
            "source": "sess = tf.InteractiveSession()\n#Now we create a TensorFlow session, since we are in an interactive context within a Jupiter notebook we use the interactive session.\n#A session is the way to deploy a TensorFlow execution graph, onto a specific execution context like a CPU or GPU.", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 14
        }, 
        {
            "source": "tf.global_variables_initializer().run()\n#Then we initialize all global variables, since this hasn't been done. Remember, the chest has only expressed the computation of graph. Now it's time to bring it to life. ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 19
        }, 
        {
            "source": "#After the variables have been initialized, it's time to create our GradientsDescent loop.\nfor _ in range(1000):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n#So this is batch Gradienst Descent, since on each iteration, \n#we graph a hand that randomly selected examples from returning set and using the session object, \n#the ExecuteGradientDescent for those hand out examples. \n#Note that if you pass the training example as parameters to this function call, \n#in order to assign them to the previously defined placeholders. So this runs very fast.", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 22
        }, 
        {
            "source": "#Now let's evaluate our classification performance using the test set from MNIST. \ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n#So argmax returns the index of the tensor, in this case a vector, which the maximum value. \n#This may be can transform back from one hot encoding scheme to a scalar. ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 23
        }, 
        {
            "source": "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n#We use reduce mean in order to determine the amount of correctly predicted values, \n#but since correct prediction is a full in vector, we have to cast it to float in order to calculate the mean over this vector.", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 24
        }, 
        {
            "source": "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n#And again, accuracy is a note in computation of graph.\n#Therefore, we need to use the TensorFlow session in order to execute it. \n#Now the placeholders does become handy, because now we assign the test dataset to the graph. \n#And as expected, this timber regression model gives us 92 percent of accuracy. ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0.918\n"
                }
            ], 
            "execution_count": 25
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
