{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.layers.recurrent.LSTM at 0x7f88efc94588>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#LSTM layers\nfrom keras.layers.recurrent import LSTM\n\nLSTM(units=10,\n    activation='tanh',\n    recurrent_activation='hard_sigmoid',\n    recurrent_initializer='orthogonal',\n    recurrent_regularizer=None,\n    dropout=0.0, recurrent_dropout=0.0,\n    return_sequences=False)                # if return_sequences is True, you return of your LSTM won't be a simple vector but a matrix instead\n# two sets of weights\n# regular set of weight, recurrent set of weight"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.layers.embeddings.Embedding at 0x7f88efc94c88>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": " # initializing embedding layers with Keras\nfrom keras.layers.embeddings import Embedding\n\nEmbedding(input_dim=5,             #vocabulary size\n          output_dim=1,            #Output vector length \n          embeddings_initializer='uniform',\n        mask_zero=False)         # Mask zero values\n# you input sequences in an embedding layer, may or may not have different lengths\n# if you think about sentences of different length,\n# and we can use the value zero as a special value that we can then mask out.\n# So for instance, you start out with sequences of various length,\n# and then you pad those sequences with zeros to make them of the same size. Only do them mask out the zero values."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
