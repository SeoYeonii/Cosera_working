{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# https://github.com/SkymindIO/dsx codes you need on classes", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 1
        }, 
        {
            "source": "!wget https://github.com/SkymindIO/dsx/releases/download/1.0/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2018-03-15 00:03:17--  https://github.com/SkymindIO/dsx/releases/download/1.0/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\nResolving github.com (github.com)... 192.30.253.112, 192.30.253.113\nConnecting to github.com (github.com)|192.30.253.112|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github-production-release-asset-2e65be.s3.amazonaws.com/113228243/d7098d7a-f40c-11e7-9df6-5627a55ea6ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180315%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180315T050317Z&X-Amz-Expires=300&X-Amz-Signature=4d25af062dea6ff34096459e797d99d320f0e780915f1f0960d00252f2c458f8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar&response-content-type=application%2Foctet-stream [following]\n--2018-03-15 00:03:17--  https://github-production-release-asset-2e65be.s3.amazonaws.com/113228243/d7098d7a-f40c-11e7-9df6-5627a55ea6ea?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180315%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180315T050317Z&X-Amz-Expires=300&X-Amz-Signature=4d25af062dea6ff34096459e797d99d320f0e780915f1f0960d00252f2c458f8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar&response-content-type=application%2Foctet-stream\nResolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.96.115\nConnecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.96.115|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 445763450 (425M) [application/octet-stream]\nSaving to: \u2018dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\u2019\n\n100%[======================================>] 445,763,450 20.6MB/s   in 21s    \n\n2018-03-15 00:03:39 (20.0 MB/s) - \u2018dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\u2019 saved [445763450/445763450]\n\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "!wget https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2018-03-15 00:24:06--  https://raw.githubusercontent.com/SkymindIO/dsx/master/iris.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2850 (2.8K) [text/plain]\nSaving to: \u2018iris.txt\u2019\n\n100%[======================================>] 2,850       --.-K/s   in 0s      \n\n2018-03-15 00:24:07 (12.9 MB/s) - \u2018iris.txt\u2019 saved [2850/2850]\n\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "!ls *jar", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\r\n"
                }
            ], 
            "execution_count": 4
        }, 
        {
            "source": "!ls iris.tx*", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "iris.txt\r\n"
                }
            ], 
            "execution_count": 6
        }, 
        {
            "source": "! java -version", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "java version \"1.8.0\"\r\nJava(TM) SE Runtime Environment (build pxa6480sr2fp10ifix-20160125_01(SR2 FP10+IV80623))\r\nIBM J9 VM (build 2.8, JRE 1.8.0 Linux amd64-64 Compressed References 20160125_287487 (JIT enabled, AOT enabled)\r\nJ9VM - R28_20160125_0846_B287487\r\nJIT  - tr.r14.java_20151209_107110.03\r\nGC   - R28_20160125_0846_B287487_CMPRSS\r\nJ9CL - 20160125_287487)\r\nJCL - 20151231_01 based on Oracle jdk8u71-b15\r\n"
                }
            ], 
            "execution_count": 7
        }, 
        {
            "source": "! java -cp dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar skymind.dsx.IrisClassifier", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n253 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dnsns.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/traceformat.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmldsigprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/CmpCrmf.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/nashorn.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmlencprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmpkcs11impl.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmjcefips.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfj-interface.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/IBMSecureRandom.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/localedata.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfj.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/xmlencfw.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/jverbs.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/cldrdata.jar\nfile:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmsaslprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/dtfjview.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/zipfs.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmxmlcrypto.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmcmsprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmkeycert.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/healthcenter.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/gskikm.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/ibmjceprovider.jar\nfile:/usr/local/src/spark21master/ibm-java-x86_64-80/jre/lib/ext/jaccess.jar\n1537 [main] INFO org.reflections.Reflections  - Reflections took 1279 ms to scan 26 urls, producing 130092 keys and 143785 values \n2708 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 12\n2711 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\njar:file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n3138 [main] INFO org.reflections.Reflections  - Reflections took 427 ms to scan 1 urls, producing 31 keys and 227 values \n4583 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 12\n4587 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n4587 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [48]; Memory: [0.5GB];\n4587 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]\n4609 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\njar:file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar!/\n5336 [main] INFO org.reflections.Reflections  - Reflections took 727 ms to scan 1 urls, producing 421 keys and 1666 values \n5404 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n5705 [main] DEBUG org.reflections.Reflections  - going to scan these urls:\nfile:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/notebook/work/dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar\n26649 [main] INFO org.reflections.Reflections  - Reflections took 20943 ms to scan 1 urls, producing 6280 keys and 43014 values \n26721 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n26721 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n26721 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n26722 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n26722 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n26727 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ReshapeVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n26727 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.modelimport.keras.preprocessors.TensorFlowCnnToFeedForwardPreProcessor as subtype of org.deeplearning4j.nn.conf.InputPreProcessor\n26727 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.layers.CenterLossOutputLayer as subtype of org.deeplearning4j.nn.conf.layers.Layer\n26727 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.ShiftVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n26727 [main] DEBUG org.deeplearning4j.nn.conf.NeuralNetConfiguration  - Registering class for JSON serialization: org.deeplearning4j.nn.conf.graph.PoolHelperVertex as subtype of org.deeplearning4j.nn.conf.graph.GraphVertex\n26774 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n26891 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.4400002782391779\n28117 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.3516273452486162\n29208 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.15688717392525403\n30099 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.10480778400467584\n31005 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.08424521566875869\n31868 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.07400915503895934\n32620 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.06815243795636046\n33331 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.06444991197121319\n34112 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.06193231931467391\n34778 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.06012409292865586\n35659 [main] INFO skymind.dsx.IrisClassifier  - \nExamples labeled as 0 classified by model as 0: 22 times\nExamples labeled as 1 classified by model as 1: 15 times\nExamples labeled as 2 classified by model as 1: 1 times\nExamples labeled as 2 classified by model as 2: 15 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        0.9811\n Precision:       0.9792\n Recall:          0.9792\n F1 Score:        0.9785\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n"
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "!$SPARK_HOME/bin/spark-submit \\\n--class skymind.dsx.IrisClassifier \\\n--master $MASTER \\\n--files iris.txt \\\ndl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v20/spark-2.0/jars/tika-app-2.0-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v20/spark-2.0/jars/ml-event-client-scala-library-0.1.55-201709150512-allinone.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/slf4j-simple-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n18/03/15 00:41:40 INFO linalg.factory.Nd4jBackend: Loaded [CpuBackend] backend\n0 [main] INFO org.nd4j.linalg.factory.Nd4jBackend  - Loaded [CpuBackend] backend\n18/03/15 00:41:40 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n582 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n18/03/15 00:41:40 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n585 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:41:41 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1334 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:41 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n1337 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:41:42 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2134 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:42 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2136 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2726 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2728 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2730 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n2732 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n3025 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n3028 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n3317 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:43 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n3320 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:170)\r\n\tat org.nd4j.versioncheck.VersionCheck.listGitPropertiesFiles(VersionCheck.java:201)\r\n\tat org.nd4j.versioncheck.VersionCheck.getVersionInfos(VersionCheck.java:220)\r\n\tat org.nd4j.versioncheck.VersionCheck.checkVersions(VersionCheck.java:92)\r\n\tat org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:6098)\r\n\tat org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:6087)\r\n\tat org.nd4j.linalg.factory.Nd4j.<clinit>(Nd4j.java:201)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertWritables(RecordReaderMultiDataSetIterator.java:377)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.convertFeaturesOrLabels(RecordReaderMultiDataSetIterator.java:271)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.nextMultiDataSet(RecordReaderMultiDataSetIterator.java:234)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator.next(RecordReaderMultiDataSetIterator.java:177)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:306)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)\r\n\tat org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:56)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:41:43 INFO org.reflections.Reflections: Reflections took 3237 ms to scan 460 urls, producing 246271 keys and 315272 values \n3346 [main] INFO org.reflections.Reflections  - Reflections took 3237 ms to scan 460 urls, producing 246271 keys and 315272 values \n18/03/15 00:41:45 INFO nd4j.nativeblas.NativeOpsHolder: Number of threads used for NativeOps: 12\n5681 [main] INFO org.nd4j.nativeblas.NativeOpsHolder  - Number of threads used for NativeOps: 12\n18/03/15 00:41:46 INFO org.reflections.Reflections: Reflections took 425 ms to scan 1 urls, producing 31 keys and 227 values \n6111 [main] INFO org.reflections.Reflections  - Reflections took 425 ms to scan 1 urls, producing 31 keys and 227 values \n18/03/15 00:41:47 INFO nd4j.nativeblas.Nd4jBlas: Number of threads used for BLAS: 12\n7099 [main] INFO org.nd4j.nativeblas.Nd4jBlas  - Number of threads used for BLAS: 12\n18/03/15 00:41:47 INFO ops.executioner.DefaultOpExecutioner: Backend used: [CPU]; OS: [Linux]\n7101 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Backend used: [CPU]; OS: [Linux]\n18/03/15 00:41:47 INFO ops.executioner.DefaultOpExecutioner: Cores: [48]; Memory: [1.5GB];\n7101 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Cores: [48]; Memory: [1.5GB];\n18/03/15 00:41:47 INFO ops.executioner.DefaultOpExecutioner: Blas vendor: [OPENBLAS]\n7101 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner  - Blas vendor: [OPENBLAS]\n18/03/15 00:41:48 INFO org.reflections.Reflections: Reflections took 823 ms to scan 1 urls, producing 421 keys and 1666 values \n7952 [main] INFO org.reflections.Reflections  - Reflections took 823 ms to scan 1 urls, producing 421 keys and 1666 values \n18/03/15 00:41:48 INFO skymind.dsx.IrisClassifier: Build model....\n8584 [main] INFO skymind.dsx.IrisClassifier  - Build model....\n18/03/15 00:41:53 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n12816 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*. skipping.\njava.lang.NullPointerException\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n18/03/15 00:41:53 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n12818 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*]\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\n\tat org.reflections.Reflections.scan(Reflections.java:237)\n\tat org.reflections.Reflections.scan(Reflections.java:204)\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:41:59 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19616 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:41:59 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n19618 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:42:33 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n53662 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:42:33 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n53664 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:42:39 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n59478 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:42:39 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n59481 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:42:39 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n59482 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:42:39 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n59483 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:42:42 WARN org.reflections.Reflections: could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n62505 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:42:42 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n62506 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:42:45 WARN org.reflections.Reflections: could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n65099 [main] WARN org.reflections.Reflections  - could not create Dir using directory from url file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*. skipping.\r\njava.lang.NullPointerException\r\n\tat org.reflections.vfs.Vfs$DefaultUrlTypes$3.matches(Vfs.java:239)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:98)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n18/03/15 00:42:45 WARN org.reflections.Reflections: could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n65100 [main] WARN org.reflections.Reflections  - could not create Vfs.Dir from url. ignoring the exception and continuing\r\norg.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/gpfs/global_fs01/sym_shared/YPProdSpark/user/s738-0c6a3f55337817-173cb7893244/data/libs/scala-2.11/*]\r\neither use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:109)\r\n\tat org.reflections.vfs.Vfs.fromURL(Vfs.java:91)\r\n\tat org.reflections.Reflections.scan(Reflections.java:237)\r\n\tat org.reflections.Reflections.scan(Reflections.java:204)\r\n\tat org.reflections.Reflections.<init>(Reflections.java:129)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.registerSubtypes(NeuralNetConfiguration.java:466)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.configureMapper(NeuralNetConfiguration.java:421)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.initMapper(NeuralNetConfiguration.java:394)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration.<clinit>(NeuralNetConfiguration.java:123)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.build(NeuralNetConfiguration.java:1223)\r\n\tat org.deeplearning4j.nn.conf.NeuralNetConfiguration$ListBuilder.build(NeuralNetConfiguration.java:279)\r\n\tat skymind.dsx.IrisClassifier.main(IrisClassifier.java:99)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\r\n\tat java.lang.reflect.Method.invoke(Method.java:507)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:819)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:196)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:221)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "18/03/15 00:42:45 INFO org.reflections.Reflections: Reflections took 56642 ms to scan 435 urls, producing 14363 keys and 101077 values \n65633 [main] INFO org.reflections.Reflections  - Reflections took 56642 ms to scan 435 urls, producing 14363 keys and 101077 values \n18/03/15 00:42:46 INFO nn.multilayer.MultiLayerNetwork: Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n65770 [main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork  - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]\n18/03/15 00:42:46 INFO optimize.listeners.ScoreIterationListener: Score at iteration 0 is 1.4531228368329279\n66191 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 0 is 1.4531228368329279\n18/03/15 00:42:47 INFO optimize.listeners.ScoreIterationListener: Score at iteration 100 is 0.3497683359828818\n67292 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 100 is 0.3497683359828818\n18/03/15 00:42:48 INFO optimize.listeners.ScoreIterationListener: Score at iteration 200 is 0.15340448031812404\n68191 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 200 is 0.15340448031812404\n18/03/15 00:42:49 INFO optimize.listeners.ScoreIterationListener: Score at iteration 300 is 0.09616550639700672\n69007 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 300 is 0.09616550639700672\n18/03/15 00:42:50 INFO optimize.listeners.ScoreIterationListener: Score at iteration 400 is 0.07195991980781578\n69721 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 400 is 0.07195991980781578\n18/03/15 00:42:50 INFO optimize.listeners.ScoreIterationListener: Score at iteration 500 is 0.059034894021966156\n70498 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 500 is 0.059034894021966156\n18/03/15 00:42:51 INFO optimize.listeners.ScoreIterationListener: Score at iteration 600 is 0.05114344705526954\n71078 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 600 is 0.05114344705526954\n18/03/15 00:42:51 INFO optimize.listeners.ScoreIterationListener: Score at iteration 700 is 0.04579229908996711\n71666 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 700 is 0.04579229908996711\n18/03/15 00:42:52 INFO optimize.listeners.ScoreIterationListener: Score at iteration 800 is 0.041876214443541365\n72278 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 800 is 0.041876214443541365\n18/03/15 00:42:53 INFO optimize.listeners.ScoreIterationListener: Score at iteration 900 is 0.038852596253866056\n72807 [main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener  - Score at iteration 900 is 0.038852596253866056\n18/03/15 00:42:53 INFO skymind.dsx.IrisClassifier: \nExamples labeled as 0 classified by model as 0: 18 times\nExamples labeled as 1 classified by model as 1: 19 times\nExamples labeled as 2 classified by model as 1: 1 times\nExamples labeled as 2 classified by model as 2: 15 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        0.9811\n Precision:       0.9833\n Recall:          0.9792\n F1 Score:        0.9807\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n73633 [main] INFO skymind.dsx.IrisClassifier  - \nExamples labeled as 0 classified by model as 0: 18 times\nExamples labeled as 1 classified by model as 1: 19 times\nExamples labeled as 2 classified by model as 1: 1 times\nExamples labeled as 2 classified by model as 2: 15 times\n\n\n==========================Scores========================================\n # of classes:    3\n Accuracy:        0.9811\n Precision:       0.9833\n Recall:          0.9792\n F1 Score:        0.9807\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 3 classes)\n========================================================================\n"
                }
            ], 
            "execution_count": 11
        }, 
        {
            "source": "we can execute our Java code in two ways. \nIn both cases, we need to build a Hoover Jar, a jar with dependencies, ship the jar and any needed text files into the data science experience. \nOnce we have that content in the data science experience, we can either execute Java, \nship it to class path of the jar, specify the class you want to execute and execute it locally in the data science experience, \nor we can ship the jar and specify the class to execute when we ship that to spark-submit. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "==========================================================================================================================================================================================", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Code Example, MNist Classifier", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "https://github.com/deeplearning4j/dl4j-examples", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "value of each Pixel --> Feature\n28 * 28 = 784 features\nlabel is 0-9", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "reading the Data is done by Datavec\n\nbuild a nn: multilayernetwork, computation graph\n\ntrain nn: Model.fit", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!wget https://raw.githubusercontent.com/SeoYeonii/Cosera_working/master/AAD_W2_Apache%20SystemML.ipynb", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2018-03-15 01:09:28--  https://raw.githubusercontent.com/SeoYeonii/Cosera_working/master/AAD_W2_Apache%20SystemML.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3059452 (2.9M) [text/plain]\nSaving to: \u2018AAD_W2_Apache SystemML.ipynb\u2019\n\n100%[======================================>] 3,059,452   --.-K/s   in 0.05s   \n\n2018-03-15 01:09:30 (55.4 MB/s) - \u2018AAD_W2_Apache SystemML.ipynb\u2019 saved [3059452/3059452]\n\n"
                }
            ], 
            "execution_count": 12
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}