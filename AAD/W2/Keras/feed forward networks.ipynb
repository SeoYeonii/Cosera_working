{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Dense layer with activations\n# Use Dropout for regularization\n#Build a Sequential model from Dense and Dropout layers"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.layers.core.Dense at 0x7fef6692e908>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from keras.layers import Dense\n\nDense( units=10,                                        # Number of output neurons\n         activation=None,                        #  Activation function by name\n         use_bias=True,                          # Use bias term or not\n         kernel_initializer= 'glorot_uniform',\n         bias_initializer='zeros')"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 7, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.layers.core.Dropout at 0x7fef668bd0f0>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from keras.layers import Dropout\n\nDropout(rate=0,              # Fraction of units to drop\n            seed=None)  #  Random seed for reproducibility"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from keras.datasets import mnist\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nbatch_size = 128\nnum_classes = 10\nepoches = 20\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#data preprocessing\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n# devide by 255 too arrive at values that lie between zero and one\n\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_2 (Dense)              (None, 512)               401920    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 669,706\nTrainable params: 669,706\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ], 
            "source": "model = Sequential()\nmodel.add(Dense(512, activation='relu',\n          input_shape=(784,)))  # First layer only\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n                     optimizer='sgd')"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, 512)               401920    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 669,706\nTrainable params: 669,706\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ], 
            "source": "#defining and compiling your model\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu',\n           input_shape=(784,)))  # First layer only\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer='sgd', \n             metrics=['accuracy'])"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/20\n60000/60000 [==============================] - 6s - loss: 1.2133 - acc: 0.6876 - val_loss: 0.5386 - val_acc: 0.8697\nEpoch 2/20\n60000/60000 [==============================] - 6s - loss: 0.5332 - acc: 0.8504 - val_loss: 0.3774 - val_acc: 0.8957\nEpoch 3/20\n60000/60000 [==============================] - 6s - loss: 0.4233 - acc: 0.8768 - val_loss: 0.3260 - val_acc: 0.9084\nEpoch 4/20\n60000/60000 [==============================] - 6s - loss: 0.3759 - acc: 0.8909 - val_loss: 0.2949 - val_acc: 0.9157\nEpoch 5/20\n60000/60000 [==============================] - 6s - loss: 0.3453 - acc: 0.9008 - val_loss: 0.2738 - val_acc: 0.9211\nEpoch 6/20\n60000/60000 [==============================] - 6s - loss: 0.3187 - acc: 0.9072 - val_loss: 0.2580 - val_acc: 0.9246\nEpoch 7/20\n60000/60000 [==============================] - 6s - loss: 0.3009 - acc: 0.9128 - val_loss: 0.2429 - val_acc: 0.9294\nEpoch 8/20\n60000/60000 [==============================] - 6s - loss: 0.2846 - acc: 0.9176 - val_loss: 0.2306 - val_acc: 0.9355\nEpoch 9/20\n60000/60000 [==============================] - 6s - loss: 0.2697 - acc: 0.9220 - val_loss: 0.2196 - val_acc: 0.93710.922\nEpoch 10/20\n60000/60000 [==============================] - 6s - loss: 0.2562 - acc: 0.9261 - val_loss: 0.2104 - val_acc: 0.9394\nEpoch 11/20\n60000/60000 [==============================] - 6s - loss: 0.2446 - acc: 0.9291 - val_loss: 0.2009 - val_acc: 0.9415\nEpoch 12/20\n60000/60000 [==============================] - 6s - loss: 0.2332 - acc: 0.9325 - val_loss: 0.1926 - val_acc: 0.9448\nEpoch 13/20\n60000/60000 [==============================] - 6s - loss: 0.2241 - acc: 0.9351 - val_loss: 0.1850 - val_acc: 0.9460\nEpoch 14/20\n60000/60000 [==============================] - 6s - loss: 0.2161 - acc: 0.9374 - val_loss: 0.1788 - val_acc: 0.9481\nEpoch 15/20\n60000/60000 [==============================] - 6s - loss: 0.2074 - acc: 0.9398 - val_loss: 0.1726 - val_acc: 0.9496\nEpoch 16/20\n60000/60000 [==============================] - 6s - loss: 0.2001 - acc: 0.9429 - val_loss: 0.1657 - val_acc: 0.9521\nEpoch 17/20\n60000/60000 [==============================] - 6s - loss: 0.1944 - acc: 0.9427 - val_loss: 0.1605 - val_acc: 0.9539\nEpoch 18/20\n60000/60000 [==============================] - 6s - loss: 0.1872 - acc: 0.9455 - val_loss: 0.1558 - val_acc: 0.9552\nEpoch 19/20\n60000/60000 [==============================] - 7s - loss: 0.1814 - acc: 0.9481 - val_loss: 0.1518 - val_acc: 0.9559\nEpoch 20/20\n60000/60000 [==============================] - 7s - loss: 0.1772 - acc: 0.9495 - val_loss: 0.1468 - val_acc: 0.9568\nTest loss: 0.14678083419\nTest accuracy: 0.9568\n"
                }
            ], 
            "source": "model.fit(x_train, y_train, batch_size=batch_size,\n         epochs=20, validation_data=(x_test, y_test))\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
